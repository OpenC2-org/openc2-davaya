#!/usr/bin/env python
# -*- coding: utf-8 -*-

# CAVEAT UTILITOR
#
# This file was automatically generated by Grako.
#
#    https://pypi.python.org/pypi/grako/
#
# Any changes you make to it will be overwritten the next time
# the file is generated.


from __future__ import print_function, division, absolute_import, unicode_literals

from grako.buffering import Buffer
from grako.parsing import graken, Parser
from grako.util import re, RE_FLAGS, generic_main  # noqa


__all__ = [
    'pasnParser',
    'pasnSemantics',
    'main'
]

KEYWORDS = set([])


class pasnBuffer(Buffer):
    def __init__(
        self,
        text,
        whitespace=None,
        nameguard=None,
        comments_re=None,
        eol_comments_re=None,
        ignorecase=None,
        namechars='',
        **kwargs
    ):
        super(pasnBuffer, self).__init__(
            text,
            whitespace=whitespace,
            nameguard=nameguard,
            comments_re=comments_re,
            eol_comments_re=eol_comments_re,
            ignorecase=ignorecase,
            namechars=namechars,
            **kwargs
        )


class pasnParser(Parser):
    def __init__(
        self,
        whitespace=None,
        nameguard=None,
        comments_re=None,
        eol_comments_re=None,
        ignorecase=None,
        left_recursion=True,
        parseinfo=True,
        keywords=None,
        namechars='',
        buffer_class=pasnBuffer,
        **kwargs
    ):
        if keywords is None:
            keywords = KEYWORDS
        super(pasnParser, self).__init__(
            whitespace=whitespace,
            nameguard=nameguard,
            comments_re=comments_re,
            eol_comments_re=eol_comments_re,
            ignorecase=ignorecase,
            left_recursion=left_recursion,
            parseinfo=parseinfo,
            keywords=keywords,
            namechars=namechars,
            buffer_class=buffer_class,
            **kwargs
        )

    @graken()
    def _pasndoc_(self):

        def block1():
            with self._ifnot():
                with self._group():
                    self._name_()
                    self._defined_as_()
            with self._ifnot():
                self._begin_()
            self._any_()
        self._closure(block1)
        self.name_last_node('head')
        with self._optional():
            self._meta_()
        self.name_last_node('metas')

        def block4():
            self._type_()
        self._positive_closure(block4)
        self.name_last_node('types')
        self._check_eof()
        self.ast._define(
            ['head', 'metas', 'types'],
            []
        )

    @graken()
    def _meta_(self):
        self._begin_()

        def block0():
            with self._ifnot():
                self._end_()
            with self._optional():
                self._NL_()
            self._Line_()
            self.name_last_node('@')
            self._NL_()
        self._closure(block0)
        self._end_()

    @graken()
    def _type_(self):
        self._name_()
        self.name_last_node('name')
        self._defined_as_()
        self._name_()
        self.name_last_node('type')
        with self._optional():
            self._topts_()
            self.name_last_node('topts')
        with self._optional():
            self._comment_()
            self.name_last_node('tdesc')
        with self._optional():
            self._fieldlist_()
            self.name_last_node('fields')
        self.ast._define(
            ['fields', 'name', 'tdesc', 'topts', 'type'],
            []
        )

    @graken()
    def _name_(self):
        self._pattern(r'(\w|_|-)+')

    @graken()
    def _any_(self):
        self._pattern(r'(\w|_|-)+|\s+|.')

    @graken()
    def _Line_(self):
        self._pattern(r'.*')

    @graken()
    def _begin_(self):
        self._token('/*')

    @graken()
    def _end_(self):
        self._token('*/')

    @graken()
    def _defined_as_(self):
        self._token('::=')

    @graken()
    def _NL_(self):
        self._pattern(r'(\n|\r)+')

    @graken()
    def _topts_(self):
        with self._choice():
            with self._option():
                self._token('(')
                with self._group():
                    self._token('PATTERN')
                    self._any_()
            with self._option():
                with self._group():
                    self._token('Foo')
                self._token(')')
            self._error('expecting one of: Foo')

    @graken()
    def _comment_(self):
        self._token('--')
        self._pattern(r'.*')

    @graken()
    def _fieldlist_(self):
        self._token('{')

        def sep1():
            self._token(',')

        def block1():
            self._field_()
        self._closure(block1, sep=sep1)
        self.name_last_node('@')
        self._token('}')

    @graken()
    def _field_(self):

        def block0():
            with self._choice():
                with self._option():
                    with self._ifnot():
                        self._token('}')
                    with self._ifnot():
                        self._token(',')
                    with self._group():
                        self._name_()
                        self.name_last_node('name')
                        self._etag_()
                        self.name_last_node('tag')
                with self._option():
                    with self._group():
                        with self._group():
                            with self._choice():
                                with self._option():
                                    self._name_()
                                with self._option():
                                    self._token('*')
                                self._error('expecting one of: *')
                        self.name_last_node('name')
                        with self._optional():
                            self._ftag_()
                            self.name_last_node('tag')
                        self._name_()
                        self.name_last_node('type')
                        with self._optional():
                            self._fopts_()
                            self.name_last_node('fopts')
                        with self._optional():
                            self._comment_()
                            self.name_last_node('fdesc')
                self._error('no available options')
        self._closure(block0)
        self.ast._define(
            ['fdesc', 'fopts', 'name', 'tag', 'type'],
            []
        )

    @graken()
    def _etag_(self):
        self._token('(')
        self._pattern(r'\d+')
        self.name_last_node('@')
        self._token(')')

    @graken()
    def _ftag_(self):
        self._token('[')
        self._pattern(r'\d+')
        self.name_last_node('@')
        self._token(']')

    @graken()
    def _fopts_(self):
        with self._choice():
            with self._option():
                self._token('OPTIONAL')
            with self._option():
                self._token('MIN')
            with self._option():
                self._token('MAX')
            self._error('expecting one of: MAX MIN OPTIONAL')


class pasnSemantics(object):
    def pasndoc(self, ast):
        return ast

    def meta(self, ast):
        return ast

    def type(self, ast):
        return ast

    def name(self, ast):
        return ast

    def any(self, ast):
        return ast

    def Line(self, ast):
        return ast

    def begin(self, ast):
        return ast

    def end(self, ast):
        return ast

    def defined_as(self, ast):
        return ast

    def NL(self, ast):
        return ast

    def topts(self, ast):
        return ast

    def comment(self, ast):
        return ast

    def fieldlist(self, ast):
        return ast

    def field(self, ast):
        return ast

    def etag(self, ast):
        return ast

    def ftag(self, ast):
        return ast

    def fopts(self, ast):
        return ast


def main(filename, startrule, **kwargs):
    with open(filename) as f:
        text = f.read()
    parser = pasnParser(parseinfo=False)
    return parser.parse(text, startrule, filename=filename, **kwargs)

if __name__ == '__main__':
    import json
    ast = generic_main(main, pasnParser, name='pasn')
    print('AST:')
    print(ast)
    print()
    print('JSON:')
    print(json.dumps(ast, indent=2))
    print()
